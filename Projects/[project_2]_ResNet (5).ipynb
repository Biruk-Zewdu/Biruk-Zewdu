{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpa5wgpBidlB"
      },
      "source": [
        "# **EE214 Project 2: CNN (ResNet)**\n",
        "\n",
        "This is the second project for EE214 Machine Learning Basics and Practices.\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "In this project, we will **implement ResNet18 and ResNet50** and perform **a classification task on the Fashion-MNIST dataset** using these models. Additionally, we will **achieve the highest possible accuracy score using any model and by only utilizing the resources available in Colab**. This project consists of the following components:\n",
        "\n",
        "* **Part 1 (10 pts). Dataset visualization**\n",
        "* **Part 2 (30 pts). Implement Building Blocks for ResNet**\n",
        "* **Part 3 (30 pts). Implement ResNet18 and ResNet50**\n",
        "* **Part 4 (10 pts). Train and visualize the results**\n",
        "* **Part 5 (20 pts). Achieve the highest possible accuracy score.**\n",
        "\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "\n",
        "## **Important**\n",
        "\n",
        "* You have to write some description about your code and results for points in each part. For required sections, we will make the **markdown** box to write in and inform you what to write. Check **ALL** steps which have points.\n",
        "* Your **submission** must be on the KLMS and includes two formats:\n",
        "    * **[STUDENT_ID]_project1.ipynb**, e.g., 20XXXXX1.ipynb\n",
        "    * **[STUDENT_ID]_project1.pdf**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ll_AcoYHH-LI"
      },
      "outputs": [],
      "source": [
        "# Importing the Required Library\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torchsummary import summary\n",
        "\n",
        "import time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCOwm_Wnz8cC"
      },
      "source": [
        "# **Part 1 (Total 10 pts)**. Download and examine the Fashion-MNIST dataset\n",
        "- In this project, we'll use the Fashion-MNIST dataset, which consists of 28x28 grayscale images of clothing.\n",
        "- As you progress through **Part 1**, you'll download the dataset and examine its structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZyCYJxszJZ3"
      },
      "outputs": [],
      "source": [
        "# Define the transformation to be applied to the data\n",
        "transformations = transforms.Compose([transforms.ToTensor(),])\n",
        "\n",
        "# Download the FashionMNIST dataset\n",
        "train_dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transformations)\n",
        "test_dataset = datasets.FashionMNIST('./data', download=True, train=False, transform=transformations)\n",
        "\n",
        "# Create DataLoader with subset of the dataset\n",
        "def get_train_loader():\n",
        "  indices = list(range(len(train_dataset)))\n",
        "  sub_dataset_size = len(train_dataset) // 3\n",
        "  random_indices = torch.randperm(len(indices)).tolist()\n",
        "  subset_indices = random_indices[:sub_dataset_size]\n",
        "\n",
        "  train_subset = Subset(train_dataset, subset_indices)\n",
        "  train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "  return train_loader\n",
        "\n",
        "train_loader = get_train_loader()\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "print(\"Number of training data: %d\" % len(train_dataset))\n",
        "print(\"Number of test data: %d\" % len(test_dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **$\\color{red}{\\text{ToDo}}$**: Visualize the dataset as shown in the illustration below. You don't need to replicate the exact results, but make sure to satisfy the following three conditions:\n",
        "\n",
        "1. Ensure that at least one image for each label is included.\n",
        "2. Plot a total of 30 or more samples.\n",
        "3. Provide information about which label each sample belongs to alongside the plot.\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1cotGY0lWW78uaObXs1xtIKMK58OuYhAd)"
      ],
      "metadata": {
        "id": "SCliORaSq6Qz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FASHION_LABELS = {0: 'T-shirt/top', 1: 'Trouser', 2: 'Pullover', 3: 'Dress', 4: 'Coat', 5: 'Sandal', 6: 'Shirt', 7: 'Sneaker', 8: 'Bag', 9: 'Ankle boot'}\n",
        "\n",
        "def display_sample(sample_images, sample_labels):\n",
        "\n",
        "    ########## implement here ##########\n",
        "\n",
        "    ####################################\n",
        "\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "# display a sample\n",
        "data_iter = iter(train_loader)\n",
        "images, labels = next(data_iter)\n",
        "print(f'images.shape = {images.shape}, labels.shape={labels.shape}')\n",
        "display_sample(images.cpu().numpy(), labels.cpu().numpy())"
      ],
      "metadata": {
        "id": "BRhujJcjSNUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zdjy1Zyy0eIB"
      },
      "source": [
        "# **Part 2 (Total 30 pts)**. Implement Building Blocks for ResNet\n",
        "\n",
        "\n",
        "- In ResNet, residual networks are implemented using the following two methods. The first is the Identity method, which uses a simple structure, as shown in the figure below. The second is the Projection method, which scales the dimensions through 1x1 convolution operations to reduce the number of parameters.\n",
        "\n",
        "  <img src=\"https://drive.google.com/uc?export=view&id=16QzhXGKVS2XVxDf-5Nz-PZjQRL0dyntO\" width=\"600\" height=\"300\" />\n",
        "\n",
        "- In **Part 2**, we will implement the two types of blocks used in ResNet, the basic block and the bottleneck block."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 1 (Total 15 pts)**. Implement BasicBlock class\n",
        "\n",
        "This class implements a basic building block for the Residual Network (ResNet) architecture. ResNet's design incorporates \"shortcut\" or \"skip connections\" to allow the gradient to be directly backpropagated through the network, addressing the vanishing/exploding gradient problem found in deeper networks. Each `BasicBlock` represents a residual block with two convolutional layers and a skip connection.\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "### **$\\color{red}{\\text{ToDo}}$**: Fill in the blanks in the skeleton code below to complete the BasicBlock class. As can be seen in the following diagram, the BasicBlock consists of following elements:\n",
        "\n",
        "```\n",
        "(A 3x3 convolution that returns a vector of dimensions out_channels)\n",
        " ➡ (batch normalization)\n",
        " ➡ (relu)\n",
        " ➡ (A 3x3 convolution that returns a vector of dimensions out_channels)\n",
        " ➡ (batch normalization)\n",
        " ➡ residual with input vector\n",
        " ➡ relu\n",
        "```\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "The detailed guide for each element is as follows:\n",
        "\n",
        "\n",
        "**1. First Convolution:**\n",
        "   - When input data is given, this data first passes through a 3x3 convolutional layer.\n",
        "   - During this process, depending on the 'stride' value, the size of the feature map may reduce.\n",
        "   - After this operation, the number of channels changes to the value defined by the 'out_channels' parameter.\n",
        "\n",
        "**2. Batch Normalization:**\n",
        "   - The result after the convolution operation undergoes batch normalization.\n",
        "   - This step normalizes each channel so that the mean is 0 and the variance is 1, increasing the stability of the network.\n",
        "\n",
        "**3. Application of ReLU Activation Function:**\n",
        "   - The result of batch normalization passes through the ReLU activation function, introducing non-linearity.\n",
        "   - This aids the model in learning more complex patterns and features.\n",
        "\n",
        "**4. Second Convolution:**\n",
        "   - Next, the activated feature map passes through a second 3x3 convolutional layer.\n",
        "   - The number of channels remains 'out_channels' here as well, and 'stride' is set to 1, meaning the size of the feature map remains unchanged.\n",
        "\n",
        "**5. Second Batch Normalization:**\n",
        "   - The result after the second convolution operation also undergoes batch normalization.\n",
        "\n",
        "**6. Addition of the Shortcut:**\n",
        "   - The original input (also known as the Residual or Shortcut) is added to the transformed feature map at this point.\n",
        "   - If the dimensions of the input and output differ, the input is adjusted through a 1x1 convolution + batch normalization for dimension matching.\n",
        "   - If the dimensions are the same, the original input is added directly without any alteration.\n",
        "   - This step is crucial as it allows the network to retain fundamental information from the input data while still detecting changes.\n",
        "\n",
        "**7. Application of the Final ReLU Activation Function:**\n",
        "   - The result, combined from the shortcut and the convolution path, passes through the ReLU activation function once more.\n",
        "   - This output is either passed on to the next layer or used as the final output, depending on the network's structure.\n",
        "\n"
      ],
      "metadata": {
        "id": "XxOEYs7uo1t6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "########## implement this class ##########\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Implements a BasicBlock architecture.\n",
        "\n",
        "    Attributes:\n",
        "    -----------\n",
        "    expansion : int\n",
        "        Class attribute representing the expansion factor for the block's output channels. For\n",
        "        `BasicBlock`, this is always 1 as there is no expansion within the block itself.\n",
        "\n",
        "    conv1 : nn.Conv2d\n",
        "        The first convolutional layer in the block, applying filters to the input data with a\n",
        "        kernel size of 3x3. The stride can be adjusted, affecting the output's height and width\n",
        "        and serving as a mechanism for spatial down-sampling. This layer does not use bias.\n",
        "\n",
        "    bn1 : nn.BatchNorm2d\n",
        "        Batch Normalization for stabilizing the inputs to the second layer by adjusting and\n",
        "        scaling the activations. Applied to the outputs of `conv1`.\n",
        "\n",
        "    relu1 : nn.ReLU\n",
        "        ReLU activation function applied after first batch normalization, introducing\n",
        "        non-linearity and enhancing the network's learning capabilities.\n",
        "\n",
        "    conv2 : nn.Conv2d\n",
        "        The second convolutional layer with the same kernel size as `conv1` but with a fixed\n",
        "        stride of 1, preserving the spatial dimensions of the data. This layer also does not use bias.\n",
        "\n",
        "    bn2 : nn.BatchNorm2d\n",
        "        Similar to `bn1`, this Batch Normalization layer normalizes the output from `conv2`,\n",
        "        ensuring that the network remains stable during training.\n",
        "\n",
        "    shortcut : nn.Sequential\n",
        "        The skip connection providing a pathway for the original input to bypass the convolutional\n",
        "        layers, facilitating the gradient flow during backpropagation. If the input and output dimensions\n",
        "        are consistent, this remains an empty sequential block. If they differ (often due to a change\n",
        "        in stride), this pathway adjusts the input's dimensions to match the output using a 1x1 convolution.\n",
        "\n",
        "    Methods:\n",
        "    --------\n",
        "    __init__(self, input_channels: int, output_channels: int, stride: int = 1) -> None:\n",
        "        Constructs all the necessary attributes for the BasicBlock object, including the convolutional\n",
        "        layers, batch normalization, and the shortcut connection.\n",
        "\n",
        "    forward(self, x: Tensor) -> Tensor:\n",
        "        Defines the computation performed at every call, applying both convolutional layers to the input,\n",
        "        then combining the output with the original input (the \"shortcut\") before returning the\n",
        "        final activated result. This method is crucial for the 'torch.nn.Module' interface, as it handles\n",
        "        the block's operations on input data.\n",
        "    \"\"\"\n",
        "\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "\n",
        "        # TODO: Define the first convolutional layer and batch normalization.\n",
        "        # Remember to consider the number of input and output channels and the stride.\n",
        "        # self.conv1 = ...\n",
        "        # self.bn1 = ...\n",
        "\n",
        "        # TODO: Define the second convolutional layer and batch normalization.\n",
        "        # The number of output channels remains the same as the first layer.\n",
        "        # self.conv2 = ...\n",
        "        # self.bn2 = ...\n",
        "\n",
        "        # TODO: Define a shortcut layer that appropriately transforms the input to be added to the transformed feature map up to this point.\n",
        "        # If input and output are the same dimensions, use an empty sequential model.\n",
        "        # If the dimensions are different, adjust the layers accordingly using 1x1 convolution + batch normalization.\n",
        "        # self.shortcut = ...\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO: Implement the forward function that applies the layers you have defined in the __init__.\n",
        "        # Don't forget to add the input x to the output of the convolutional layers (skip connection).\n",
        "        # return ..."
      ],
      "metadata": {
        "id": "-yvRFf0DvPsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 2 (Total 15 pts)**. Implement Bottleneck block\n",
        "\n",
        "This class implements the \"Bottleneck\" building block used in deeper Residual Network (ResNet) architectures. These blocks are designed with efficiency in mind, providing a more efficient way of increasing the depth of the network without a significant increase in computational complexity. The main feature of a Bottleneck block is the use of 1x1 convolutions to reduce and subsequently restore dimensions, ensuring that the 3x3 convolution has a minimal computational load.\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "### **$\\color{red}{\\text{ToDo}}$**: Fill in the blanks in the skeleton code below to complete the Bottleneck class. As can be seen in the following diagram, the Bottleneck class consists of following elements:\n",
        "\n",
        "```\n",
        "(A 1x1 convolution that returns a vector of dimensions out_channels)\n",
        " ➡ (batch normalization)\n",
        " ➡ (relu)\n",
        " ➡ (A 3x3 convolution that returns a vector of dimensions out_channels)\n",
        " ➡ (batch normalization)\n",
        " ➡ (relu)\n",
        " ➡ (A 1x1 convolution that returns a vector of dimensions out_channels*4)\n",
        " ➡ (batch normalization)\n",
        " ➡ residual with input vector\n",
        " ➡ relu\n",
        "```\n",
        "\n",
        "**1. First Convolution (1x1 kernels):**\n",
        "   - The data first passes through a 1x1 convolutional layer. Despite its simplicity, this layer is instrumental in reducing the dimensionality, as it affects the depth of the feature maps (i.e., the number of channels).\n",
        "   - This layer performs initial feature transformation, preparing the data for the next step of processing.\n",
        "\n",
        "**2. First Batch Normalization and ReLU Activation:**\n",
        "   - Subsequent to convolution, the model normalizes the batch using Batch Normalization. This step is crucial for maintaining consistent mean and variance, improving the stability and speed of the training process.\n",
        "   - After normalization, the feature map goes through a ReLU activation function, providing the non-linearity necessary for the model to learn complex patterns.\n",
        "\n",
        "**3. Second Convolution (3x3 kernels):**\n",
        "   - The second layer is a 3x3 convolution, the central part of the bottleneck. It's where the spatial features are primarily learned, without any change in the depth of the feature maps.\n",
        "   - This convolution is more computational efficient due to the reduced dimensionality from the previous 1x1 convolution.\n",
        "\n",
        "**4. Second Batch Normalization and ReLU Activation:**\n",
        "   - The model normalizes the results of the second convolution before applying another ReLU activation.\n",
        "   - This step is necessary for ensuring the model does not produce outputs with high variance or learn inefficient representations.\n",
        "\n",
        "**5. Third Convolution (1x1 kernels):**\n",
        "   - The third layer involves another 1x1 convolution. This stage is crucial as it restores the depth of the feature maps, often expanding it to be ready for addition with the shortcut.\n",
        "   - It allows the network to learn more abstract features by reintroducing depth to the feature maps.\n",
        "\n",
        "**6. Third Batch Normalization:**\n",
        "   - Similar to previous layers, batch normalization is applied to standardize the feature maps, preparing them for the shortcut connection.\n",
        "\n",
        "**7. Shortcut Connection and Final ReLU Activation:**\n",
        "   - The shortcut (or residual connection) is then added back to the main pathway. If the input needs to be resized to match the output dimensions, a 1x1 convolution is applied to the shortcut connection.\n",
        "   - After adding the shortcut, the block applies a ReLU activation function to introduce non-linearity, making the output the final result of this block."
      ],
      "metadata": {
        "id": "K4RulCIJpNFr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "########## implement this class ##########\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "\n",
        "    \"\"\"\n",
        "    Implements a Bottleneck architecture.\n",
        "\n",
        "    Attributes:\n",
        "    -----------\n",
        "    expansion : int\n",
        "        Class attribute representing the expansion factor for the output channels at the end of\n",
        "        the block. This attribute multiplies the number of channels in the block, typically\n",
        "        increasing the depth by 4 times in a standard Bottleneck block.\n",
        "\n",
        "    conv1 : nn.Conv2d\n",
        "        The first layer in the bottleneck, a 1x1 convolution. This layer reduces the number of\n",
        "        channels, preparing the input for the next 3x3 convolution. It is designed without a bias term.\n",
        "\n",
        "    bn1 : nn.BatchNorm2d\n",
        "        Batch Normalization for the first convolution, stabilizing the activations and improving\n",
        "        the training process.\n",
        "\n",
        "    relu1 : nn.ReLU\n",
        "        ReLU activation function applied after first batch normalization, introducing\n",
        "        non-linearity and enhancing the network's learning capabilities.\n",
        "\n",
        "    conv2 : nn.Conv2d\n",
        "        The central layer of the bottleneck, a 3x3 convolution. This layer maintains the number\n",
        "        of channels but can alter the spatial dimensions based on the stride. It is also designed\n",
        "        without a bias term.\n",
        "\n",
        "    bn2 : nn.BatchNorm2d\n",
        "        Batch Normalization for the central convolutional layer, providing the same benefits as `bn1`.\n",
        "\n",
        "    relu2 : nn.ReLU\n",
        "        ReLU activation function applied after central batch normalization.\n",
        "\n",
        "    conv3 : nn.Conv2d\n",
        "        The final layer in the bottleneck, a 1x1 convolution. This layer expands the number of\n",
        "        channels by the factor defined in `expansion`, increasing the depth of the feature map.\n",
        "        This convolution is also without a bias term.\n",
        "\n",
        "    bn3 : nn.BatchNorm2d\n",
        "        Batch Normalization for the final convolution, ensuring the network's stability as the depth increases.\n",
        "\n",
        "    shortcut : nn.Sequential\n",
        "        A sequential container for the 'shortcut' or 'skip connection'. When the input and output\n",
        "        dimensions differ, due to either a stride not equal to 1 or a difference in the number of channels,\n",
        "        this pathway contains a 1x1 convolution that adjusts the input's dimensions to match the output.\n",
        "\n",
        "    Methods:\n",
        "    --------\n",
        "    __init__(self, in_channels: int, out_channels: int, stride: int = 1) -> None:\n",
        "        Initializes the Bottleneck block with its convolutional layers, batch normalization,\n",
        "        and prepares the shortcut connection.\n",
        "\n",
        "    forward(self, x: Tensor) -> Tensor:\n",
        "        Defines the computation performed at every call. The input passes through each layer of the\n",
        "        bottleneck, with a skip connection adding the input of the block to its output. This method\n",
        "        applies the ReLU activation function after each addition and finally returns the resulting tensor.\n",
        "    \"\"\"\n",
        "\n",
        "    # This value is used to adjust the number of output channels in the layer, e.g., out_channels * expansion.\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "\n",
        "        # TODO: Define the first 1x1 convolution layer.\n",
        "        # It should take in_channels and return out_channels.\n",
        "        # self.conv1 = ...\n",
        "        # self.bn1 = ...\n",
        "        # self.relu1 = ...\n",
        "\n",
        "        # TODO: Define the second 3x3 convolution layer.\n",
        "        # It should take out_channels and return out_channels, possibly performing downsampling using stride and padding.\n",
        "        # self.conv2 = ...\n",
        "        # self.bn2 = ...\n",
        "        # self.relu2 = ...\n",
        "\n",
        "        # TODO: Define the third 1x1 convolution layer.\n",
        "        # It should take out_channels and return out_channels * expansion.\n",
        "        # self.conv3 = ...\n",
        "        # self.bn3 = ...\n",
        "\n",
        "        # Shortcut definition for skip connection\n",
        "        self.shortcut = nn.Sequential()  # Default is identity (no-operation)\n",
        "        if stride != 1 or in_channels != out_channels * self.expansion:\n",
        "            # TODO: Add a layer to adjust dimensions in the shortcut path, if necessary, using 1x1 convolution + batch normalization.\n",
        "            # self.shortcut = ...\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO: Implement the forward function that applies the layers you have defined in the __init__.\n",
        "        # Don't forget to add the input x to the output of the convolutional layers (skip connection).\n",
        "\n",
        "        return out  # Return the final output"
      ],
      "metadata": {
        "id": "S89iM4QL5ksu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRFsbTrVq6DH"
      },
      "source": [
        "# **Part 3 (Total 30 pts)**. Implement ResNet18 and ResNet50\n",
        "- In **Part 3**, we will implement ResNet18 and ResNet50 using the Basic block and Bottleneck block that we implemented in Part 2.\n",
        "- The architectural configuration of ResNet18 and ResNet50 is as shown in the figure below, and one [*] represents a basic/bottleneck block.\n",
        "\n",
        "  <img src=\"https://drive.google.com/uc?export=view&id=1lY6jHixjUNKYpiw0Nho0XyLzlHuvhmGh\" width=\"700\" height=\"330\" />\n",
        "- First, we will implement a common ResNet class that can be used to build both ResNet18 and ResNet50, and through this, we will create each model."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 1 (Total 25 pts)**. Implement ResNet Class\n",
        "\n",
        "### **$\\color{red}{\\text{ToDo}}$**: Using the detailed description provided, complete the ResNet class by filling in the blanks in the following skeleton code.\n",
        "\n",
        "**1. Initial Setup:**\n",
        "   - ResNet class initializes with parameters specifying the type of block to use, the number of blocks, and the number of classes for classification.\n",
        "   - The initial number of channels, specifically, `in_channels`, is set to 64.\n",
        "\n",
        "**2. Initial Convolutional Layer and Max Pooling:**\n",
        "\n",
        "   - Initial Convolutional Layer: This layer (`self.conv1`) employs 64 filters of size 7x7 with a stride of 2 and padding of 3.\n",
        "\n",
        "   - Batch Normalization: Following the convolution, the model applies batch normalization via `self.bn1` to standardize the activations of the previous layer. This process helps stabilize and accelerate the learning process.\n",
        "\n",
        "   - ReLU Activation: After the convolution, the model applies a ReLU activation function (`self.relu`).\n",
        "\n",
        "   - Max Pooling: Subsequent to the initial convolutional layers, the ResNet model incorporates a max-pooling layer (`self.maxpool`). This layer, with a kernel size of 3x3, stride of 2, and padding of 1, reduces the spatial dimensions by taking the maximum value of features, helping the model eliminate redundant information and retain only crucial features.\n",
        "\n",
        "**3. Constructing Residual Layers:**\n",
        "   - Four main layers (each a sequence of blocks) follow the initial convolution. Each layer uses the `_make_layer` function to create a series of residual blocks.\n",
        "   - `self.layer1` is composed of `num_blocks[0]` blocks, each outputting 64 channels and using a stride of 1 for maintaining the spatial dimensions of the feature maps.\n",
        "   - `self.layer2` consists of `num_blocks[1]` blocks, increasing the number of channels to 128. With the appropriate stride, it effectively halves the dimensions of the feature maps while increasing their depth for a more complex feature representation.\n",
        "   - `self.layer3` is structured with `num_blocks[2]` blocks, further enhancing the capacity by increasing the channels to 256. It continues the trend of reducing spatial dimensions by half and doubling the depth, allowing the network to learn even more complex patterns in the input data.\n",
        "   - `self.layer4` forms the deepest segment of the architecture, comprising `num_blocks[3]` blocks, each contributing to a total of 512 channels. This layer continues to compact the spatial dimensions and enhance the representational depth, making the network capable of understanding highly abstract features present in the data.\n",
        "\n",
        "\n",
        "**4. Residual Block Creation (`_make_layer` method):**\n",
        "   - This method creates a sequence of residual blocks. The first block in each sequence might use a stride not equal to 1 for dimensionality reduction.\n",
        "   - For each block, it adjusts the number of input channels (`self.in_channels`) and the number of output channels, ensuring that the subsequent block receives the correct number of input channels.\n",
        "   - It stacks these blocks sequentially to form a complete layer.\n",
        "\n",
        "**5. Forward Pass:**\n",
        "   - The `forward` method defines the data flow through the network:\n",
        "     - The input data `x` goes through the initial convolution, batch normalization, and ReLU activation.\n",
        "     - It then sequentially passes through each of the four layers of residual blocks (`self.layer1`, `self.layer2`, `self.layer3`, `self.layer4`).\n",
        "     - Following the residual layers, a global average pooling is performed reducing the spatial dimensions to 1x1.\n",
        "     - The pooled output is then flattened and finally, a linear layer (`self.linear`) classifies the features into `num_classes` categories."
      ],
      "metadata": {
        "id": "S0fIPC9so7Zx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "########## implement this class ##########\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "      \"\"\"\n",
        "      Implements a Residual Network (ResNet) architecture.\n",
        "\n",
        "      The ResNet architecture is designed with deep residual learning to ease the training of\n",
        "      networks that are substantially deeper than those used previously. This class creates a\n",
        "      customizable ResNet model by stacking layers of residual blocks, performing initial\n",
        "      convolution, and final classification using a fully connected layer.\n",
        "\n",
        "      Attributes:\n",
        "      -----------\n",
        "      in_channels : int\n",
        "          The number of channels in the input data. Initialized to 64 for the first layer.\n",
        "      conv1 : nn.Conv2d\n",
        "          The first convolutional layer which applies 64 filters with a 7x7 kernel, stride of 2,\n",
        "          and padding of 3.\n",
        "      bn1 : nn.BatchNorm2d\n",
        "          Batch Normalization for the first convolutional layer.\n",
        "      relu : nn.ReLU\n",
        "          ReLU activation function used after batch normalization.\n",
        "      maxpool : nn.MaxPool2d\n",
        "          Max pooling with a 3x3 kernel, stride of 2, and padding of 1.\n",
        "      layer1-4 : nn.Sequential\n",
        "          Layers of residual blocks, with the number of blocks and output channels varying\n",
        "          per layer. Each individual layer is created by the _make_layer private method.\n",
        "      linear : nn.Linear\n",
        "          The final fully connected layer that outputs the classification results.\n",
        "\n",
        "      Methods:\n",
        "      --------\n",
        "      __init__(self, block, num_blocks, num_classes=10):\n",
        "          Initializes the ResNet with the given block type, list of integers representing the\n",
        "          number of blocks in each layer, and the number of classification classes.\n",
        "\n",
        "      _make_layer(self, block, output_channels, num_blocks, stride):\n",
        "          Helper function to create a layer of residual blocks with the specified number of blocks,\n",
        "          output channels, and the initial stride.\n",
        "\n",
        "      forward(self, x):\n",
        "          Defines the forward pass of the input through the ResNet architecture. The input data 'x'\n",
        "          passes sequentially through the initial convolution (with batch normalization and ReLU),\n",
        "          max pooling, four residual layers, and finally, the fully connected layer for classification.\n",
        "          The output of this method is the classification result of the input.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_channels = 64  # Starting number of channels\n",
        "\n",
        "        # TODO: Define the initial convolutional layer and batch normalization.\n",
        "        # self.conv1 = ...\n",
        "        # self.bn1 = ...\n",
        "        # self.relu = ...\n",
        "        # self.maxpool = ...\n",
        "\n",
        "        # Define layers consisting of BasicBlocks. Each layer may contain multiple blocks.\n",
        "        # The number of blocks for each layer is specified in num_blocks.\n",
        "        # TODO: Define the four layers of the ResNet (self.layer1 to self.layer4) using the '_make_layer' function.\n",
        "        # self.layer1 = ...\n",
        "        # self.layer2 = ...\n",
        "        # self.layer3 = ...\n",
        "        # self.layer4 = ...\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
        "\n",
        "        # TODO: Define the final fully connected layer that maps the output of the convolutional layers to the classes.\n",
        "        # self.linear = ...\n",
        "\n",
        "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
        "        # This function creates a sequential layer for each set of blocks.\n",
        "        # TODO: Implement the function that creates each layer. You will need to consider the stride for the first block\n",
        "        # and make sure subsequent blocks maintain the output dimension.\n",
        "        # Update self.in_channels as needed.\n",
        "        # return ...\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO: Implement the forward function. Apply the layers defined in the __init__ to the input x.\n",
        "        # Finally, apply average pooling and a fully connected layer for the classification.\n",
        "        # return ..."
      ],
      "metadata": {
        "id": "YVep11fmvqVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 2 (Total 5 pts)**. Construct and check your ResNet18 and ResNet50"
      ],
      "metadata": {
        "id": "Po1dnH1z_wEN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OiBVJSDIXqjL"
      },
      "outputs": [],
      "source": [
        "# Define the ResNet18 model using the previously defined BasicBlock and ResNet class.\n",
        "resnet18_model = ResNet(block=BasicBlock,\n",
        "                   num_blocks=[2, 2, 2, 2],\n",
        "                   num_classes=10)\n",
        "summary(resnet18_model, (1, 28, 28))\n",
        "\n",
        "# Define the ResNet50 model using the previously defined Bottleneck block and ResNet class.\n",
        "resnet50_model = model = ResNet(block=Bottleneck,\n",
        "                   num_blocks=[3, 4, 6, 3],\n",
        "                   num_classes=10)\n",
        "summary(resnet50_model, (1, 28, 28))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCcgpSK6wzn8"
      },
      "source": [
        "# **Part 4 (Total 10 pts)**. Train and visualize the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RD5-GqQdx46b"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "random_seed = 7\n",
        "learning_rate = 0.001\n",
        "batch_size = 128\n",
        "num_epochs = 5\n",
        "\n",
        "# Architecture\n",
        "NUM_FEATURES = 28*28\n",
        "NUM_CLASSES = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PVYoyEePXqjN"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "def calculate_metric(metric_fn, true_y, pred_y):\n",
        "    try:\n",
        "      return metric_fn(true_y, pred_y, average=\"macro\")\n",
        "    except:\n",
        "      return metric_fn(true_y, pred_y)\n",
        "\n",
        "def print_scores(p, r, f1, a, batch_size):\n",
        "    for name, scores in zip((\"precision\", \"recall\", \"F1\", \"accuracy\"), (p, r, f1, a)):\n",
        "        print(f\"\\t{name.rjust(14, ' ')}: {sum(scores)/batch_size:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTyjgkkNwy8k"
      },
      "outputs": [],
      "source": [
        "def compute_accuracy(model, data_loader):\n",
        "    correct_pred, num_examples = 0, 0\n",
        "    for i, (features, targets) in enumerate(data_loader):\n",
        "\n",
        "        logits, probas = model(features)\n",
        "        _, predicted_labels = torch.max(probas, 1)\n",
        "        num_examples += targets.size(0)\n",
        "        correct_pred += (predicted_labels == targets).sum()\n",
        "    return correct_pred.float()/num_examples * 100\n",
        "\n",
        "\n",
        "def train(model, optimizer):\n",
        "    losses = []\n",
        "    val_batches = len(test_loader)\n",
        "\n",
        "    start_time = time.time()\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "\n",
        "        # ----------------- TRAINING  --------------------\n",
        "        # set model to training\n",
        "\n",
        "        train_loader = get_train_loader()\n",
        "        batches = len(train_loader)\n",
        "\n",
        "        model.train()\n",
        "        for batch_idx, (features, targets) in enumerate(train_loader):\n",
        "            logits = model(features)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            current_loss = loss.item()\n",
        "            total_loss += current_loss\n",
        "\n",
        "            if not batch_idx % 10:\n",
        "                print ('Epoch: %d/%d | Batch %d/%d | loss: %.4f' %(epoch+1, num_epochs, batch_idx, len(train_loader), current_loss))\n",
        "\n",
        "        # ----------------- VALIDATION  -----------------\n",
        "        val_losses = 0\n",
        "        precision, recall, f1, accuracy = [], [], [], []\n",
        "\n",
        "        # set model to evaluating (testing)\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (features, targets) in enumerate(test_loader):\n",
        "\n",
        "                logits = model(features) # this get's the prediction from the network\n",
        "\n",
        "                val_losses += F.cross_entropy(logits, targets)\n",
        "\n",
        "                predicted_classes = torch.max(logits, 1)[1] # get class from network's prediction\n",
        "\n",
        "                # calculate P/R/F1/A metrics for batch\n",
        "                for acc, metric in zip((precision, recall, f1, accuracy),\n",
        "                                    (precision_score, recall_score, f1_score, accuracy_score)):\n",
        "                    acc.append(\n",
        "                        calculate_metric(metric, targets.cpu(), predicted_classes.cpu())\n",
        "                    )\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, training loss: {total_loss/batches}, validation loss: {val_losses/val_batches}\")\n",
        "        print_scores(precision, recall, f1, accuracy, val_batches)\n",
        "        losses.append(total_loss/batches) # for plotting learning curve\n",
        "\n",
        "    print('Total Training Time: %.2f min' % ((time.time() - start_time)/60))\n",
        "\n",
        "    return losses"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 1 (Total 5 pts)**. Train the ResNet18 and display the training and testing losses for ResNet18 as a graph.\n",
        "### **$\\color{red}{\\text{ToDo}}$**: Train your ResNet18 using below code and plot the training loss and validation loss against the epochs. (You can modify the training code as needed.)"
      ],
      "metadata": {
        "id": "h6qvy8KXqfo7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0uhoJEBXqjN"
      },
      "outputs": [],
      "source": [
        "num_epochs = 5\n",
        "optimizer = torch.optim.Adam(resnet18_model.parameters(), lr=learning_rate)\n",
        "\n",
        "losses = train(resnet18_model, optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 2 (Total 5 pts)**. Train the ResNet50 and display the training and testing losses for ResNet50 as a graph.\n",
        "### **$\\color{red}{\\text{ToDo}}$**: Train your ResNet50 using below code and plot the training loss and validation loss against the epochs. (You can modify the training code as needed.)"
      ],
      "metadata": {
        "id": "AAFcgq99uEpK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3zqnhdcxzv1"
      },
      "outputs": [],
      "source": [
        "num_epochs = 5\n",
        "optimizer = torch.optim.Adam(resnet50_model.parameters(), lr=learning_rate)\n",
        "\n",
        "losses = train(resnet50_model, optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # **Part 5 (Total 20 pts)**. Achieve the highest possible **accuracy score** on the test dataset for the Fashion-MNIST classification task using only the basic Colab resources.\n",
        "\n",
        "* **You can use any model**, including the ResNet you implemented, as long as **it can be trained within the Colab resources**.\n",
        "* To receive points for your score, **the model and the training process used to achieve that score must be accurately documented in your submitted file.**\n",
        "* You may modify `train_loader`, `train()` as necessary, but `test_loader` should not be modified.\n",
        "\n",
        "- Part5 score will be given based on the achieved accuracy score like the followings:\n",
        "  - 0.93 ~ : 20 pts\n",
        "  - 0.90 ~ 0.93 : 15 pts\n",
        "  - 0.88 ~ 0.90 : 10 pts\n",
        "  - 0.85 ~ 0.88 : 5 pts\n"
      ],
      "metadata": {
        "id": "KZhLVZZdIeUQ"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}